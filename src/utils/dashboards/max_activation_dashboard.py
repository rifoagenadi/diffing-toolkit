from typing import Any, Dict, List, Optional, Tuple
import streamlit as st
import numpy as np
from src.utils.visualization import (
    filter_examples_by_search,
    create_examples_html,
    render_streamlit_html,
)

class MaxActivationDashboardComponent:
    """
    Reusable Streamlit component for displaying MaxActStore contents.
    
    Features:
    - Mandatory latent selection (if latents exist) via text input
    - Optional quantile filtering via selectbox
    - Text search functionality
    - Lazy loading with pagination for performance
    - Batch database queries for efficient retrieval
    - Prepared for hybrid preview/full detail modes
    """

    def __init__(self, max_store, title: str = "Maximum Activating Examples", 
                 initial_batch_size: int = 15, batch_size: int = 10):
        """
        
        Args:
            max_store: ReadOnlyMaxActStore or MaxActStore instance
            title: Title for the dashboard
            initial_batch_size: Number of examples to load initially
            batch_size: Number of examples to load in each subsequent batch
        """
        self.max_store = max_store
        self.title = title
        self.initial_batch_size = initial_batch_size
        self.batch_size = batch_size

    def _get_available_latents(self) -> List[int]:
        """Get list of available latent indices from the database."""
        return self.max_store.get_available_latents()

    def _get_available_quantiles(self) -> List[int]:
        """Get list of available quantile indices from the database."""
        return self.max_store.get_available_quantiles()

    def _get_available_datasets(self) -> List[str]:
        """Get list of available dataset names from the database."""
        return self.max_store.get_available_datasets()

    def _convert_maxstore_to_dashboard_format(self, examples: List[Dict[str, Any]], 
                                            detail_mode: str = "full") -> List[Tuple[float, List[str], List[float], str]]:
        """
        Convert MaxActStore examples to dashboard format with support for different detail modes.
        
        Args:
            examples: List of examples from MaxActStore.get_top_examples()
            detail_mode: "preview" for quick display, "full" for complete visualization
            
        Returns:
            List of tuples (max_score, tokens, scores_per_token, text)
        """
        if not examples:
            return []
            
        # Assumption: MaxActStore has tokenizer for token conversion
        assert self.max_store.tokenizer is not None, "MaxActStore must have tokenizer for visualization"
        
        if detail_mode == "preview":
            # Preview mode: just return basic info without detailed scores
            dashboard_examples = []
            for example in examples:
                tokens = self.max_store.tokenizer.convert_ids_to_tokens(example["input_ids"])
                # Use uniform scores for preview (all zeros)
                scores_per_token = np.zeros(len(tokens))
                example_tuple = [
                    example["max_score"],
                    tokens,
                    scores_per_token,
                    example["text"],
                ]
                if "dataset_name" in example and example["dataset_name"] is not None:
                    example_tuple.append(example["dataset_name"])
                dashboard_examples.append(tuple(example_tuple))
            return dashboard_examples
        
        # Full mode: get detailed activation scores
        example_ids = [ex["example_id"] for ex in examples]
        
        # Use batch method for efficient database access
        detailed_examples = self.max_store.get_batch_example_details(example_ids, return_dense=True)
        
        # Create lookup dictionary for efficient matching
        details_dict = {ex["example_id"]: ex for ex in detailed_examples}
        
        dashboard_examples = []
        for example in examples:
            example_id = example["example_id"]
            
            # Get detailed info if available
            if example_id in details_dict:
                details = details_dict[example_id]
                # Assumption: All examples must have scores_per_token for full visualization
                assert "scores_per_token" in details, f"Example {example_id} missing scores_per_token - cannot visualize in full mode"
                
                tokens = self.max_store.tokenizer.convert_ids_to_tokens(example["input_ids"])
                scores_per_token = np.array(details["scores_per_token"])
                
                # Shape assertion
                assert len(tokens) == len(scores_per_token), f"Token/score mismatch: {len(tokens)} tokens vs {len(scores_per_token)} scores"
            else:
                # Fallback to basic display if details not available
                tokens = self.max_store.tokenizer.convert_ids_to_tokens(example["input_ids"])
                scores_per_token = np.zeros(len(tokens))
            
            example_tuple = [
                example["max_score"],
                tokens,
                scores_per_token,
                example["text"]
            ]
            if "dataset_name" in example and example["dataset_name"] is not None:
                example_tuple.append(example["dataset_name"])
            dashboard_examples.append(tuple(example_tuple))
                    
        return dashboard_examples

    def _get_session_keys(self, selected_latent: Optional[int], selected_quantile: Optional[int], 
                         selected_datasets: List[str], search_term: str) -> Dict[str, str]:
        """Generate session state keys based on current filters."""
        datasets_hash = hash(tuple(sorted(selected_datasets))) % 10000 if selected_datasets else 0
        db_path_hash = hash(str(self.max_store.db_manager.db_path)) % 10000
        base_key = f"maxact_{selected_latent}_{selected_quantile}_{datasets_hash}_{db_path_hash}_{hash(search_term) % 10000}"
        return {
            "examples": f"{base_key}_examples",
            "loaded_count": f"{base_key}_loaded_count", 
            "total_count": f"{base_key}_total_count",
            "loading": f"{base_key}_loading"
        }

    def _load_examples_batch(self, selected_latent: Optional[int], selected_quantile: Optional[int], 
                           selected_datasets: List[str], start_idx: int, batch_size: int) -> List[Dict[str, Any]]:
        """Load a batch of examples with offset and limit."""
        # Get all examples with filters but limit to batch size with offset
        all_examples = self.max_store.get_top_examples(
            latent_idx=selected_latent,
            quantile_idx=selected_quantile,
            dataset_names=selected_datasets if selected_datasets else None
        )
        
        # Apply offset and limit
        end_idx = start_idx + batch_size
        return all_examples[start_idx:end_idx]

    def display(self):
        """Render the dashboard component with lazy loading."""

        st.markdown(f"### {self.title}")
        
        # Get available filter options
        available_latents = self._get_available_latents()
        available_quantiles = self._get_available_quantiles()
        available_datasets = self._get_available_datasets()
        
        # Initialize filter values
        selected_latent = None
        selected_quantile = None
        selected_datasets = []
        
        # Latent selection (mandatory if latents exist)
        if available_latents:
            col1, col2 = st.columns([2, 1])
            with col1:
                latent_input = st.number_input(
                    "Latent Index (required)",
                    min_value=min(available_latents),
                    max_value=max(available_latents),
                    value=available_latents[0],
                    step=1,
                    help=f"Available latent indices: {min(available_latents)}-{max(available_latents)}"
                )
                
                # Validate the input
                if latent_input in available_latents:
                    selected_latent = latent_input
                else:
                    st.error(f"Latent index {latent_input} not available. Available indices: {available_latents[:10]}{'...' if len(available_latents) > 10 else ''}")
                    return
            
            with col2:
                st.metric("Available Latents", len(available_latents))
        
        # Quantile selection (optional)
        if available_quantiles:
            quantile_options = ["All"] + [str(q) for q in available_quantiles]
            selected_quantile_str = st.selectbox(
                "Quantile Filter",
                options=quantile_options,
                help="Filter by quantile index (optional)"
            )
            
            if selected_quantile_str != "All":
                selected_quantile = int(selected_quantile_str)
        
        # Dataset selection (optional)
        if available_datasets:
            selected_datasets = st.multiselect(
                "Dataset Filter",
                options=available_datasets,
                default=[],
                help="Filter by dataset names (optional). Leave empty to show all datasets."
            )
        
        # Search functionality
        search_term = st.text_input(
            "üîç Search in examples",
            placeholder="Enter text to search for in the examples...",
        )
        
        # For methods without latents, we can still proceed
        if available_latents and selected_latent is None:
            st.info("Please select a latent index to view examples.")
            return
        
        # Generate session state keys
        session_keys = self._get_session_keys(selected_latent, selected_quantile, selected_datasets, search_term)
        
        # Initialize session state
        if session_keys["examples"] not in st.session_state:
            st.session_state[session_keys["examples"]] = []
            st.session_state[session_keys["loaded_count"]] = 0
            st.session_state[session_keys["total_count"]] = None
            st.session_state[session_keys["loading"]] = False
        
        # Reset if filters changed (check by comparing with a hash)
        current_filter_hash = hash((selected_latent, selected_quantile, tuple(sorted(selected_datasets)), search_term))
        last_filter_key = f"{session_keys['examples']}_filter_hash"
        if last_filter_key not in st.session_state or st.session_state[last_filter_key] != current_filter_hash:
            st.session_state[session_keys["examples"]] = []
            st.session_state[session_keys["loaded_count"]] = 0
            st.session_state[session_keys["total_count"]] = None
            st.session_state[last_filter_key] = current_filter_hash
        
        # Load initial batch if nothing loaded yet
        if not st.session_state[session_keys["examples"]] and not st.session_state[session_keys["loading"]]:
            st.session_state[session_keys["loading"]] = True
            
            # Get total count first
            all_examples_for_count = self.max_store.get_top_examples(
                latent_idx=selected_latent,
                quantile_idx=selected_quantile,
                dataset_names=selected_datasets if selected_datasets else None
            )
            st.session_state[session_keys["total_count"]] = len(all_examples_for_count)
            
            # Load initial batch
            initial_examples = self._load_examples_batch(
                selected_latent, selected_quantile, selected_datasets, 0, self.initial_batch_size
            )
            st.session_state[session_keys["examples"]] = initial_examples
            st.session_state[session_keys["loaded_count"]] = len(initial_examples)
            st.session_state[session_keys["loading"]] = False

        
        # Get current examples from session state
        loaded_examples = st.session_state[session_keys["examples"]]
        total_count = st.session_state[session_keys["total_count"]] or 0
        loaded_count = st.session_state[session_keys["loaded_count"]]
        
        # Apply search filter to loaded examples
        dashboard_examples = self._convert_maxstore_to_dashboard_format(loaded_examples, detail_mode="full")
        if search_term.strip():
            dashboard_examples = filter_examples_by_search(dashboard_examples, search_term)

        # Calculate dataset distribution
        if loaded_examples:
            dataset_counts = {}
            for example in loaded_examples:
                dataset_name = example.get("dataset_name", "Unknown")
                dataset_counts[dataset_name] = dataset_counts.get(dataset_name, 0) + 1
            
            total_loaded = len(loaded_examples)
            dataset_fractions = {name: count / total_loaded for name, count in dataset_counts.items()}
            
            # Display dataset distribution (always show, even for single datasets)
            if len(dataset_counts) >= 1:
                if len(dataset_counts) == 1:
                    dataset_name = list(dataset_counts.keys())[0]
                    st.caption(f"Dataset: {dataset_name} ({total_loaded} examples)")
                else:
                    fraction_parts = [f"{name}: {fraction:.1%}" for name, fraction in dataset_fractions.items()]
                    st.caption(f"Dataset distribution in loaded examples: {', '.join(fraction_parts)}")
        
        # Build filter context message
        filter_parts = []
        if selected_latent is not None:
            filter_parts.append(f"Latent {selected_latent}")
        if selected_quantile is not None:
            filter_parts.append(f"Quantile {selected_quantile}")
        if selected_datasets:
            if len(selected_datasets) == 1:
                filter_parts.append(f"Dataset: {selected_datasets[0]}")
            else:
                filter_parts.append(f"Datasets: {', '.join(selected_datasets[:2])}{' (+{} more)'.format(len(selected_datasets) - 2) if len(selected_datasets) > 2 else ''}")
        if search_term.strip():
            filter_parts.append(f"Search: '{search_term}'")
        
        # Display status and load more button
        col1, col2 = st.columns([3, 1])
        
        with col1:
            context_msg = f"Showing {len(dashboard_examples)} examples"
            if search_term.strip():
                context_msg += f" (from {loaded_count} loaded, {total_count} total)"
            else:
                context_msg += f" ({loaded_count} of {total_count} loaded)"
            
            if filter_parts:
                context_msg += f" - {', '.join(filter_parts)}"
            
            st.info(context_msg)
        
        with col2:
            # Show load more button if there are more examples to load
            has_more = loaded_count < total_count
            if has_more and st.button(f"Load {min(self.batch_size, total_count - loaded_count)} More", 
                                     disabled=st.session_state[session_keys["loading"]]):
                st.session_state[session_keys["loading"]] = True
                
                # Load next batch
                next_batch = self._load_examples_batch(
                    selected_latent, selected_quantile, selected_datasets, loaded_count, self.batch_size
                )
                
                # Append to existing examples
                st.session_state[session_keys["examples"]].extend(next_batch)
                st.session_state[session_keys["loaded_count"]] += len(next_batch)
                st.session_state[session_keys["loading"]] = False
                
                # Rerun to update display
                st.rerun()
        
        # Check if we have examples to show
        if not dashboard_examples:
            if search_term.strip():
                st.warning("No examples found matching your search. Try loading more examples or changing your search term.")
            else:
                st.warning("No examples found with the selected filters.")
            return
        
        # Create and render HTML visualization
        title_with_filters = self.title
        if filter_parts:
            title_with_filters += f" - {', '.join(filter_parts)}"
        
        html_content = create_examples_html(
            dashboard_examples,
            self.max_store.tokenizer,
            title=title_with_filters,
            max_examples=len(dashboard_examples),  # Show all loaded examples
            window_size=50,
            use_absolute_max=False,
        )
        
        # Render in Streamlit
        render_streamlit_html(html_content)
